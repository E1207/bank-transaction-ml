{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîß Preprocessing et Feature Engineering\n",
    "## Santander Customer Transaction Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Biblioth√®ques import√©es\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "print('‚úÖ Biblioth√®ques import√©es')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (200000, 200)\n",
      "y_train: (200000,)\n",
      "X_test: (200000, 200)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "X_train = train.drop(['ID_code', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "X_test = test.drop(['ID_code'], axis=1)\n",
    "\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "print(f'X_test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouvelles features cr√©√©es: 11\n"
     ]
    }
   ],
   "source": [
    "def add_statistical_features(df):\n",
    "    df_new = df.copy()\n",
    "    df_new['mean'] = df.mean(axis=1)\n",
    "    df_new['std'] = df.std(axis=1)\n",
    "    df_new['min'] = df.min(axis=1)\n",
    "    df_new['max'] = df.max(axis=1)\n",
    "    df_new['median'] = df.median(axis=1)\n",
    "    df_new['skew'] = df.skew(axis=1)\n",
    "    df_new['kurt'] = df.kurtosis(axis=1)\n",
    "    df_new['range'] = df_new['max'] - df_new['min']\n",
    "    df_new['q1'] = df.quantile(0.25, axis=1)\n",
    "    df_new['q3'] = df.quantile(0.75, axis=1)\n",
    "    df_new['iqr'] = df_new['q3'] - df_new['q1']\n",
    "    return df_new\n",
    "\n",
    "X_train_eng = add_statistical_features(X_train)\n",
    "X_test_eng = add_statistical_features(X_test)\n",
    "\n",
    "print(f'Nouvelles features cr√©√©es: {X_train_eng.shape[1] - X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 100 features s√©lectionn√©es\n"
     ]
    }
   ],
   "source": [
    "k_best = 100\n",
    "selector = SelectKBest(score_func=f_classif, k=k_best)\n",
    "selector.fit(X_train_eng, y_train)\n",
    "\n",
    "scores = pd.DataFrame({'feature': X_train_eng.columns, 'score': selector.scores_}).sort_values('score', ascending=False)\n",
    "selected_features = scores.head(k_best)['feature'].tolist()\n",
    "\n",
    "X_train_selected = X_train_eng[selected_features]\n",
    "X_test_selected = X_test_eng[selected_features]\n",
    "\n",
    "print(f'‚úÖ {len(selected_features)} features s√©lectionn√©es')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Normalisation effectu√©e\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=selected_features, index=X_train_selected.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=selected_features, index=X_test_selected.index)\n",
    "\n",
    "print('‚úÖ Normalisation effectu√©e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scaler sauvegard√©\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "print('‚úÖ Scaler sauvegard√©')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Preprocessing termin√© !\n",
    "\n",
    "Prochaine √©tape: Modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
