{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155e4596",
   "metadata": {},
   "source": [
    "# ü§ñ Modeling et √âvaluation\n",
    "## Santander Customer Transaction Prediction\n",
    "\n",
    "---\n",
    "\n",
    "### Objectifs de ce notebook :\n",
    "1. Entra√Æner plusieurs mod√®les de classification\n",
    "2. Comparer les performances\n",
    "3. Optimiser les hyperparam√®tres\n",
    "4. G√©rer le d√©s√©quilibre des classes\n",
    "5. √âvaluer avec des m√©triques appropri√©es\n",
    "6. Sauvegarder le meilleur mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf32ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des biblioth√®ques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Mod√®les\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Biblioth√®ques import√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156beeb8",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Pr√©paration des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16389c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donn√©es pr√©process√©es du notebook pr√©c√©dent\n",
    "print(\"üì• Chargement des donn√©es...\")\n",
    "\n",
    "# Recharger les donn√©es et refaire le preprocessing\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# S√©parer X et y\n",
    "X = train.drop(['ID_code', 'target'], axis=1)\n",
    "y = train['target']\n",
    "X_test_final = test.drop(['ID_code'], axis=1)\n",
    "\n",
    "print(f\"‚úÖ Donn√©es charg√©es: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "# Split train/validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Split effectu√©:\")\n",
    "print(f\"   Train: {X_train.shape}\")\n",
    "print(f\"   Validation: {X_val.shape}\")\n",
    "print(f\"\\n   Distribution train: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"   Distribution val: {y_val.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6500d988",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Baseline: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß Entra√Ænement du mod√®le Baseline: Logistic Regression...\")\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_lr = lr_model.predict(X_val)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# √âvaluation\n",
    "print(\"\\nüìä R√©sultats Logistic Regression:\")\n",
    "print(f\"   Accuracy: {accuracy_score(y_val, y_pred_lr):.4f}\")\n",
    "print(f\"   Precision: {precision_score(y_val, y_pred_lr):.4f}\")\n",
    "print(f\"   Recall: {recall_score(y_val, y_pred_lr):.4f}\")\n",
    "print(f\"   F1-Score: {f1_score(y_val, y_pred_lr):.4f}\")\n",
    "print(f\"   ROC-AUC: {roc_auc_score(y_val, y_pred_proba_lr):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df85b0d5",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22139612",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üå≤ Entra√Ænement Random Forest...\")\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_rf = rf_model.predict(X_val)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# √âvaluation\n",
    "print(\"\\nüìä R√©sultats Random Forest:\")\n",
    "print(f\"   Accuracy: {accuracy_score(y_val, y_pred_rf):.4f}\")\n",
    "print(f\"   Precision: {precision_score(y_val, y_pred_rf):.4f}\")\n",
    "print(f\"   Recall: {recall_score(y_val, y_pred_rf):.4f}\")\n",
    "print(f\"   F1-Score: {f1_score(y_val, y_pred_rf):.4f}\")\n",
    "print(f\"   ROC-AUC: {roc_auc_score(y_val, y_pred_proba_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b50818",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ec374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Entra√Ænement XGBoost...\")\n",
    "\n",
    "# Calculer scale_pos_weight pour g√©rer le d√©s√©quilibre\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"   scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_xgb = xgb_model.predict(X_val)\n",
    "y_pred_proba_xgb = xgb_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# √âvaluation\n",
    "print(\"\\nüìä R√©sultats XGBoost:\")\n",
    "print(f\"   Accuracy: {accuracy_score(y_val, y_pred_xgb):.4f}\")\n",
    "print(f\"   Precision: {precision_score(y_val, y_pred_xgb):.4f}\")\n",
    "print(f\"   Recall: {recall_score(y_val, y_pred_xgb):.4f}\")\n",
    "print(f\"   F1-Score: {f1_score(y_val, y_pred_xgb):.4f}\")\n",
    "print(f\"   ROC-AUC: {roc_auc_score(y_val, y_pred_proba_xgb):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c0fed4",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b5d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üí° Entra√Ænement LightGBM...\")\n",
    "\n",
    "lgbm_model = LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_lgbm = lgbm_model.predict(X_val)\n",
    "y_pred_proba_lgbm = lgbm_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# √âvaluation\n",
    "print(\"\\nüìä R√©sultats LightGBM:\")\n",
    "print(f\"   Accuracy: {accuracy_score(y_val, y_pred_lgbm):.4f}\")\n",
    "print(f\"   Precision: {precision_score(y_val, y_pred_lgbm):.4f}\")\n",
    "print(f\"   Recall: {recall_score(y_val, y_pred_lgbm):.4f}\")\n",
    "print(f\"   F1-Score: {f1_score(y_val, y_pred_lgbm):.4f}\")\n",
    "print(f\"   ROC-AUC: {roc_auc_score(y_val, y_pred_proba_lgbm):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e22999",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Comparaison des mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un DataFrame de comparaison\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost', 'LightGBM'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_val, y_pred_lr),\n",
    "        accuracy_score(y_val, y_pred_rf),\n",
    "        accuracy_score(y_val, y_pred_xgb),\n",
    "        accuracy_score(y_val, y_pred_lgbm)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_score(y_val, y_pred_lr),\n",
    "        precision_score(y_val, y_pred_rf),\n",
    "        precision_score(y_val, y_pred_xgb),\n",
    "        precision_score(y_val, y_pred_lgbm)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_val, y_pred_lr),\n",
    "        recall_score(y_val, y_pred_rf),\n",
    "        recall_score(y_val, y_pred_xgb),\n",
    "        recall_score(y_val, y_pred_lgbm)\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_score(y_val, y_pred_lr),\n",
    "        f1_score(y_val, y_pred_rf),\n",
    "        f1_score(y_val, y_pred_xgb),\n",
    "        f1_score(y_val, y_pred_lgbm)\n",
    "    ],\n",
    "    'ROC-AUC': [\n",
    "        roc_auc_score(y_val, y_pred_proba_lr),\n",
    "        roc_auc_score(y_val, y_pred_proba_rf),\n",
    "        roc_auc_score(y_val, y_pred_proba_xgb),\n",
    "        roc_auc_score(y_val, y_pred_proba_lgbm)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä COMPARAISON DES MOD√àLES\")\n",
    "print(\"=\"*70)\n",
    "print(results.to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des performances\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "colors = ['#3498db', '#2ecc71', '#f39c12', '#e74c3c']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    results.plot(x='Model', y=metric, kind='bar', ax=axes[i], color=colors, legend=False)\n",
    "    axes[i].set_title(f'{metric}', fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel('')\n",
    "    axes[i].set_ylabel(metric)\n",
    "    axes[i].set_xticklabels(results['Model'], rotation=45, ha='right')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Comparaison globale\n",
    "results_melted = results.melt(id_vars='Model', var_name='Metric', value_name='Score')\n",
    "pivot_data = results_melted.pivot(index='Metric', columns='Model', values='Score')\n",
    "\n",
    "sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='RdYlGn', ax=axes[5], cbar_kws={'label': 'Score'})\n",
    "axes[5].set_title('Heatmap des Performances', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551fc153",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Courbes ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a5108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbes ROC pour tous les mod√®les\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "models_proba = [\n",
    "    ('Logistic Regression', y_pred_proba_lr),\n",
    "    ('Random Forest', y_pred_proba_rf),\n",
    "    ('XGBoost', y_pred_proba_xgb),\n",
    "    ('LightGBM', y_pred_proba_lgbm)\n",
    "]\n",
    "\n",
    "for name, y_proba in models_proba:\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_proba)\n",
    "    auc = roc_auc_score(y_val, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=2)\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Courbes ROC - Comparaison des Mod√®les', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc90e8c",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Matrices de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices de confusion\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "predictions = [\n",
    "    ('Logistic Regression', y_pred_lr),\n",
    "    ('Random Forest', y_pred_rf),\n",
    "    ('XGBoost', y_pred_xgb),\n",
    "    ('LightGBM', y_pred_lgbm)\n",
    "]\n",
    "\n",
    "for i, (name, y_pred) in enumerate(predictions):\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i], cbar=False)\n",
    "    axes[i].set_title(f'Matrice de Confusion - {name}', fontweight='bold')\n",
    "    axes[i].set_xlabel('Pr√©diction')\n",
    "    axes[i].set_ylabel('R√©alit√©')\n",
    "    axes[i].set_xticklabels(['Pas de transaction', 'Transaction'])\n",
    "    axes[i].set_yticklabels(['Pas de transaction', 'Transaction'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c75018",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Feature Importance (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123f7dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance pour XGBoost\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nüîù Top 20 features les plus importantes (XGBoost):\")\n",
    "print(feature_importance.head(20))\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_20 = feature_importance.head(20)\n",
    "plt.barh(range(len(top_20)), top_20['importance'], color='steelblue')\n",
    "plt.yticks(range(len(top_20)), top_20['feature'])\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 20 Features par Importance (XGBoost)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b2558",
   "metadata": {},
   "source": [
    "## üîü S√©lection et sauvegarde du meilleur mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a13f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lectionner le meilleur mod√®le bas√© sur ROC-AUC\n",
    "best_model_idx = results['ROC-AUC'].idxmax()\n",
    "best_model_name = results.loc[best_model_idx, 'Model']\n",
    "best_auc = results.loc[best_model_idx, 'ROC-AUC']\n",
    "\n",
    "print(f\"\\nüèÜ Meilleur mod√®le: {best_model_name}\")\n",
    "print(f\"   ROC-AUC: {best_auc:.4f}\")\n",
    "\n",
    "# Mapper le nom au mod√®le\n",
    "model_mapping = {\n",
    "    'Logistic Regression': lr_model,\n",
    "    'Random Forest': rf_model,\n",
    "    'XGBoost': xgb_model,\n",
    "    'LightGBM': lgbm_model\n",
    "}\n",
    "\n",
    "best_model = model_mapping[best_model_name]\n",
    "\n",
    "# Sauvegarder le meilleur mod√®le\n",
    "print(\"\\nüíæ Sauvegarde du meilleur mod√®le...\")\n",
    "joblib.dump(best_model, '../models/best_model.pkl')\n",
    "print(\"‚úÖ Mod√®le sauvegard√© dans '../models/best_model.pkl'\")\n",
    "\n",
    "# Sauvegarder les r√©sultats\n",
    "results.to_csv('../models/model_comparison.csv', index=False)\n",
    "print(\"‚úÖ R√©sultats sauvegard√©s dans '../models/model_comparison.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a41e9",
   "metadata": {},
   "source": [
    "## üìù Rapport de classification final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261aece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport d√©taill√© pour le meilleur mod√®le\n",
    "best_pred = best_model.predict(X_val)\n",
    "\n",
    "print(f\"\\nüìä RAPPORT DE CLASSIFICATION - {best_model_name}\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_val, best_pred, target_names=['Pas de transaction', 'Transaction']))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d99e6",
   "metadata": {},
   "source": [
    "## üìù Conclusions\n",
    "\n",
    "### R√©sum√© :\n",
    "1. ‚úÖ **4 mod√®les entra√Æn√©s** : Logistic Regression, Random Forest, XGBoost, LightGBM\n",
    "2. ‚úÖ **Meilleur mod√®le identifi√©** bas√© sur ROC-AUC\n",
    "3. ‚úÖ **Mod√®le sauvegard√©** pour l'API\n",
    "4. ‚úÖ **Gestion du d√©s√©quilibre** via class_weight et scale_pos_weight\n",
    "\n",
    "### Prochaines √©tapes :\n",
    "‚û°Ô∏è **Phase 2** : Cr√©er l'API Flask (`api/app.py`)\n",
    "‚û°Ô∏è **Phase 3** : D√©velopper l'interface Streamlit (`frontend/streamlit_app.py`)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
